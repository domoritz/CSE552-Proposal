\documentclass[11pt]{scrartcl}

\usepackage{natbib}
\usepackage{geometry}
\usepackage{amsmath,amsthm,amssymb,url}
\usepackage{fullpage}
\usepackage{tabularx}
\usepackage{float}
\usepackage{microtype}
\usepackage[pdftex]{hyperref}

\usepackage[final]{graphicx}
\usepackage{xcolor}
\definecolor{darkblue}{rgb}{0,0,0.5}
\usepackage{transparent}

\usepackage{enumitem}
\setlist{nolistsep}

\setlength{\parskip}{3px}

%\addtolength{\topmargin}{-.5in}
%\addtolength{\textheight}{1.2in}

\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}

\newenvironment{theorem}[2][Theorem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{lemma}[2][Lemma]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{exercise}[2][Exercise]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{question}[2][Question]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}
\newenvironment{corollary}[2][Corollary]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2.}]}{\end{trivlist}}

\begin{document}

\title{Visualizing Physical Query Execution in a Relational Big Data Management System}
%\subtitle{Project Description \--- Distributed Systems}
\author{Shumo Chu and Dominik Moritz}
\date{}

\maketitle

\section{Introduction}
We developed a visualization system that gives its users an intuitive interface for understanding and exploring query execution in distributed database system. Our system collects profiling logs of query execution in distributed workers, aggregates, and then shows query processing at three granularities to enable inspection at the resolution that best reflects problems or insights. This allows users to efficiently debug and improve queries. It also allows developers to improve query processing. An example of our visualization can be seen in Figure~\ref{fig:fig1}.

\begin{figure}[H]
  \begin{center}
    \includegraphics[width=.95\textwidth]{figure1}
  \end{center}
  \caption{Visualization of fragment execution and worker utilization with focus on the first two seconds.}
  \label{fig:fig1}
\end{figure}

In particular, our visualization system is built to inspect query execution in Myria, a distributed big data management system currently being developed in the UW CSE database group. Myria aims towards building a distributed database platform to provide \emph{big data management and analytics as a service} primarily for scientific applications.  Myria takes queries in high level query languages and then translates them into physical query plans, which will be executed in parallel. After submitting a query, the a user can only get the query result and the running time. In practice an user would like to ask questions like why this query is slow, why the result of this query is so large/small, etc. These questions are challenging and difficult for Myria and other current big data systems to answer. With our visualization system, Myria users can interactively explore the visualization of query processing to find the answers to these questions.

Notably, the abstraction level of Myria that our visualization system interacts with, is the physical plan layer. Most current distributed database systems supporting structured or semi-structured data model, like Pig, Hive and Shark \cite{pig, hive, XinRZFSS13SIGMOD}, share a similar design for this layer. Thus, our visualization approach is general to relational big data systems.


\section{Background and motivation}

This section describes how queries are executed in the Myria system and how our project helps us to understand the execution of physical query plans.


\subsection{Query processing in Myria}
\label{sec:background}

Myria transforms user's query in the languages that it supports, eg. SQL, Datalog, or MyriaL\footnote{MyriaL is a PigLatin like language} into a physical query plan. Physical query plan can be thought of as the "execution map" of a query. Usually it can be represented as a \emph{Directed acyclic graph} (DAG), which consists of basic operators, e.g. \emph{JOIN}, \emph{GROUP BY}, \emph{SCAN}, \emph{APPLY} as vertices and the data flows between different operators as edges. Besides the operators that usually exist in sequential relational database systems, Myria also has a \emph{SHUFFLE} operator to route the tuples in a sharded table to workers according to the hashes of specified column(s).

\begin{figure}
 \begin{center}
     \includegraphics[width=0.7\textwidth]{myria_arch.pdf}
   \end{center}
  \caption{Myria System Architecture.}
  \label{fig:myria_arc}
\end{figure}

Figure~\ref{fig:myria_arc} shows the system architecture of Myria. It contains three parts, a front-end consisting web UI and query optimizer, a master consisting REST API server and coordinator and distributed query execution engine called MyriaX.  

When a query is submitted by a user, the front-end translates this query into a physical query plan using its query optimizer. Then it submits the physical query plan to the master through the REST server. The coordinator gets the physical plan from the REST sever and begins to call MyriaX to execute the physical plan.

For example, the SQL query $SELECT \; R.*, S.*  \; WHERE \; R.x=S.y ;$ can be translated to the query plan shown in Figure~\ref{fig:query_plan}. The semantics of the query plan is a distributed hash join of two tables, $R$ and $S$. We first need to hash each table according to the joined fields. Then tuples are shuffled by their hash results to different workers. At each worker, the shuffled tuples are joined locally. A query fragment is a subtree of the query execution plan that is separated from the rest of the plan by a network boundary. The example has three query fragments denoted by different colors.

Each query fragment runs in a separate thread on each worker and is separated from other query fragments by a network boundary. Myria's execution model is asynchronous and pull-based within one fragment and push-based between fragments. This means that within one query fragment an operator calls its children to fetch data (\texttt{fetchNextReady}). A child can either return \texttt{null} if no or not enough data is ready or a tuple batch. The query fragments form a DAG. inside one query fragment, the operators form a tree. Fragment leaves and roots are typically I/O operators. When a root operator in a query fragment is a shuffle producer, it shuffles tuples to other fragments.

\begin{figure}
 \begin{center}
     \includegraphics[width=0.5\textwidth]{join.pdf}
   \end{center}
  \caption{Query plan: distributed hash join using three query fragments.}
  \label{fig:query_plan}
\end{figure}

The Myria database is written in Java and communicates using protocol buffers. The Myria web front-end server is written in Python and runs on Google App Engine\footnote{\url{https://developers.google.com/appengine/}}.


\subsection{Goals}
\label{sec:objective}

Database system profiling has been extensively studied over decades. There are two types of works on this topic. One is logging query execution information and analyzing logs afterwards for better query optimization. The other is using real-time profiling information to estimate the progress of a query. We focus on the first type of problem in the context of distributed database system.

Our system has to collect information about the execution of a physical query plan in Myria, which provides the foundation for analyzing the data and creating a meaningful visualization. The visualization is embedded in a web application.

\vspace{5px}

\noindent Questions that we want to answer with this project:

\begin{enumerate}
  \item What are the data dependencies between operators in workers?
  \item What is the bottleneck of the execution? Improving which part could improve the performance the most?
  \item Is there a slow worker during a certain stage of the execution that prevent the progress of the whole query plan?
  \item Is the data skewed in a way that prevents efficient usage of available workers?

\end{enumerate}

%We do not try to build a visualization that can visualize long running queries with many states for each query fragment as we do not expect to get different insights into the general query execution, skew and data flow from queries that run longer. Performance is, for now, not a main goal of the project. However, since we can have many workers and multiple query fragments, which will prevent us from showing all profiling data in one view.


\section{Related work}

Twitter developed Ambrose\cite{ambrose}, a platform for visualization and real-time monitoring of MapReduce data workflows. They offer three different views to show associated jobs, job dependencies and progress. Ambrose has been released as open source. Ambrose, however, is not suitable for our needs as the abstraction level of jobs is too high and does not capture single operators.

Google's Dapper\cite{sigelman2010dapper} is a distributed systems tracing infrastructure and offers fine grained tracing of calls in Google's distributed systems. They also proposed an interface for visualizing traces. Twitter closely modeled Zipkin\cite{zipkin} after Dapper and released it as open source. Our system is similar to Dapper and Zipkin as it has a similar architecture and offers similar visualizations. However, we offer different abstraction levels, which enables users to find problems faster and handle larger amounts of profiling data. Also, our visualization is specifically designed to help developers understand query execution in distributed database system like Myria as opposed to general traces in distributed systems.

Tools to visualize query plans for example in SQL Server, as used to improve performance for the SDSS Sky survey\cite{szalay2002sdss}, focus on optimizing queries and not query execution and have no visualization of data flow, which is necessary to optimize physical query execution.


\section{Design and implementation}

\subsection{System Design}
Figure~\ref{fig:vis_arch} shows the architecture of our visualization system. We log relevant events in each worker. After executing a query, logs stored in workers are collected by the log coordinator on the maser node and then aggregated and  stored to the log database. When there is a request for visualization data from the web UI, the visualization REST server will extract the specific data requested from the log DB and transform it to the JSON format and send it to web UI.  The aim of this design is to have the minimal affect on the query performance yet make the visualization system highly modular for future improvement. For example, using the REST API, anyone can implement their own visualization front-end to meet special need.

\begin{figure}
 \begin{center}
     \includegraphics[width=0.7\textwidth]{viz_arch.pdf}
   \end{center}
  \caption{Architecture of the visualization system}
  \label{fig:vis_arch}
\end{figure}

In Section~\ref{sec:logging} and \ref{sec:collect}, we will describe how we collect performance data using logging and what the logs tell us about the query execution. In Section~\ref{sec:visualization}, we will focus on how we present the collected information to help us as developers to understand the performance impact of skew or certain operators on the running time.

\subsection{Logging}
\label{sec:logging}

In our visualization, we want to capture the state of operators, query fragments, and workers. A state is similar to a span in Dapper\cite{sigelman2010dapper}.

The state of a query fragment depends on the state of the operators inside it and the state of a worker depends on the state of the query fragments that are running on it. Consequently, we only need to capture the state of query fragments per worker. In order to capture state changes, we log events and state changes of operators.

Not all operators have the same states. A consumer for example does not have a wait, compute or send state. Table~\ref{tbl:state} shows the different states operators can be in and briefly describes their meaning. Note that sleep and wait are different. Waiting means that an operator is waiting for child operator to return from a function call and sleep means that an operator has to be woken up by new incoming data to the fragment.

\begin{table}[h]
\begin{tabularx}{\textwidth}{ l|X|X|X }
 & \multicolumn{3}{ c }{operator type} \\
\cline{2-4}
state & producers (pushes to other fragments) & consumers (receive from other fragments) & operations \newline (\emph{JOIN}, \emph{MERGE}, \emph{SCAN}, \emph{APPLY}, ...) \\
\hline \hline
receive & - & receives data from producer over network & - \\
\hline
wait & child is producing & - & waiting for child to return \\
\hline
compute & hashing data & - & in \texttt{fetchNextReady} and not waiting for any data \\
\hline
sleep & has data for consumer that is not ready & no data in producer & waiting for signal \\
\hline
send & sending data to consumer over network & - & - \\
\end{tabularx}
\caption{Possible states of operators and their meaning.}
\label{tbl:state}
\end{table}

In order to capture these states we have to log events that indicate their beginning and their end. An operator can only be in one state at a time. Consequently, the states can be reconstructed from the logs without any information about which events belong to each other. Since we also log the time of the events we can reconstruct when an operator changes its state and determine how long it has been in a certain state. We do not expect clock skew to be a problem because the intervals are coarse grained enough.

No all transitions between states are possible. For example, the wait state can only be reached from the compute state. A way to interpret this is that wait and compute are a sub-states of another state work. This interpretation is useful since a set of computes and waits can be grouped together because they were triggered by a call to \texttt{fetchNextReady} and end with a return from the function. We use this information in the visualization of operator states.

To be able to reconstruct the states mentioned in Table~\ref{tbl:state} we have to log all events that cause state changes.

As mentioned in the beginning of this section, the states of query fragments and workers can be inferred from the state of the query fragments that are executed on a worker. A query fragment can be in the state receiving when the leaf operator is a consumer (and not a scan). It can be in the state compute when any of its children are computing. It can be sleeping when the root is sleeping and it can be sending when the root is sending. Since a fragment is executed by one thread, it cannot be in multiple states.

The state of a worker is ambiguous because multiple threads can be executing multiple query fragments that are in different states. We use the state of the query fragments to show how many query fragments are working but we do not determine a single state for the whole worker.

% state changes

\subsection{Log collection}
\label{sec:collect}

For logging, we use \emph{slf4j}\footnote{\url{http://www.slf4j.org}}, a logging API, which is implemented by different logging frameworks. Dedicated logs enable us to use asynchronous logs and keep the effect on query execution small. Since logs are collected on different workers, we need to collect them to one machine (in our case the Myria master) that analyzes the data and creates the visualizations. The collecting server is a Myria master, which means that we can use its database to store the logs and then read from when we create the visualization. We have not implemented storing the data in the database yet but cache the parsed results in a compressed file on the master.

This architecture of distributed loggers and collectors is similar to the collection pipeline proposed in Dapper\cite{sigelman2010dapper}.

Logs are collected on the Myria master that offers a REST API to access the aggregated and preprocessed data. The visualization fetches data using Ajax\footnote{Asynchronous JavaScript calls to a server.} from the Myria through the App Engine server for Myria web. We use this indirection to aggregate data for visualization as we want the REST API to stay simple.


\subsection{Visualization interface}
\label{sec:visualization}

Users can switch between three levels of query execution visualization to identify the problem at the granularity that best reveals the information they need. These kinds of visualization allow developers to answer the questions from Section~\ref{sec:objective}.

A more detailed evaluation of how the visualization helped us to understand, debug and eventually improve how queries are executed will be given in Section~\ref{sec:evaluation}.

\subsubsection{Query plan level}

The query plan level visualization as seen in Figure~\ref{fig:frags} shows a line chart of utilization of the cluster for each query fragment. Utilization is measured as the fraction of workers that are executing the query fragment. By observing long tails users can identify which of the query fragments is a bottleneck. Skew can be identified in a drop in the number of workers calculating a query fragment. Without skew, the graph would go up to the maximum, stay there for most of the computation, and then go back down.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{fragments_lines}
  \end{center}
  \caption{Visualization that shows on how many workers a fragment is computing. The last fragment is the one that writes the join results to disk.}
  \label{fig:frags}
\end{figure}


\subsubsection{Query fragment level}

If a critical fragment is identified, a user can switch to the visualization at the query fragment level. This level shows the execution state of the same query fragment on different workers in a Gantt chart as seen in Figure~\ref{fig:fig1}. Possible states of a fragment are \emph{computing}, \emph{waiting}, and \emph{sleeping}. Gantt charts are used widely in the visualization of project plans because they visualize time spans and show dependencies between them. The state of a fragment is defined by the state of the root operator. Users can finally narrow down to identify which worker to explore next.

If tuples are returned from a call to \texttt{fetchNextReady}, we show the number of tuples in a tooltip. The same tooltip is used to show begin and end time and the duration for each state in the Gantt chart.

\subsubsection{Operator level}

The operator level visualization, as seen in Figure~\ref{fig:gantt}, shows a Gantt chart of the operator states for a specific query fragment. The operators of the query fragment are shown in the same hierarchy as they appear in the query subtree. For every point in time, the Gantt chart shows the operator states, \emph{computing}, \emph{waiting} (an operator waits for a call to its child to return), \emph{sleeping}, \emph{receiving}, or \emph{sleeping}. This view allows users to see which operator is the bottleneck of the query fragment and how long/how frequent an operator is waiting for data.

For the visualization of operators we want to show the hierarchical relationship between operators and allow users to focus only on certain operators. Additional information about states is shown on demand in a tooltip.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{join_gantt}
  \end{center}
  \caption{Query fragment of hash join that first consumes all tuples from S and then joins with R. Orange is computing, light orange is waiting and gray is sleeping. The small graph under the main graph allows users to select an area to focus on.}
  \label{fig:gantt}
\end{figure}


\subsubsection{Implementation}

We use D3\cite{bostock2011d3} to build the visualization. D3 is a JavaScript framework for data visualizations on the web. Consequently, our visualization will be browser based and we integrated it into the existing web interface for Myria\footnote{A demo can be found at \url{http://demo.myria.cs.washington.edu/} but it does not yet have the visualization.}.

We used the visualization technique of \emph{focus+context}\cite{furnas1986generalized} to allow users to zoom into a detail of the query execution without loosing the context of the whole query.

The data format for the visualizations is a custom JSON\footnote{JavaScript object notation} format with nested operators and an array of states per operator. The line charts use CSV\footnote{Comma separated values}.


\section{Evaluation}
\label{sec:evaluation}
We use our visualization framework to examine real world database queries. The three-level visualization helps us to gain knowledge on the execution of the query plan. We present the following use cases, which illustrates the interactive exploration of the query execution.

\noindent \textbf{Case 1: Identify slow worker(s)}.
We execute a distributed partition join as shown in Figure~\ref{fig:query_plan}. First, we examine the query level visualization (Figure~\ref{fig:slow_worker_overview}) of the query plan execution. We can observe that in the utilization line chart of fragment~0 and fragment~1, there is a long tail, which clearly shows that a single worker takes much longer than others to finish these two fragments.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{slow_worker_overview.pdf}
  \end{center}
  \caption{Query level visualization used to identify a slow worker by observing a long tail.}
  \label{fig:slow_worker_overview}
\end{figure}

To better understand this problem, we zoom to the fragment level visualization of fragment~0 (Figure~\ref{fig:slow_worker_fragment}). This figure shows that worker~1 takes much longer to finish than the rest of the workers. Since we have further narrowed down the problem on worker~1, we zoom in further to see the operator level visualization of fragment~0 on worker~1.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{slow_worker_fragment.pdf}
  \end{center}
  \caption{Fragment level visualization used to identify a slow fragment.}
  \label{fig:slow_worker_fragment}
\end{figure}

Figure~\ref{fig:slow_worker_operator} shows the operator level view. We can see the problem is the operator \emph{Scan(R)}. It takes a long time to scan the first tuple from the database and return it to the \emph{Shuffle(R)} operator. This is possibly caused by the \emph{cold start} of the database connection on worker~1.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=\textwidth]{slow_worker_operator.pdf}
  \end{center}
  \caption{Operator level visualization used to identify a slow worker.}
  \label{fig:slow_worker_operator}
\end{figure}

\noindent \textbf{Case 2: Identify bottleneck operator}.
A specific operator could be the bottleneck of the whole query execution even in the absence of skew or slow worker. This can be also identified easily through exploration on the visualization on different levels. Following the process from Case~1, we can zoom in to the operator level to find the bottleneck operator. Figure~\ref{fig:bottleneck_operator} shows the operator level view of the same query plan as Case~1 without the slow worker. We can observe that the \emph{Insert} operator takes most of time when executing the query fragment. This implies that this query plan is I/O bound. Writing the result to the database is the bottleneck of this query.

\begin{figure}[h]
  \begin{center}
	\includegraphics[width=\textwidth]{bottleneck_operator.pdf}
  \end{center}
 \caption{Operator level visualization used to identify bottleneck.}
  \label{fig:bottleneck_operator}
 \end{figure}


\section{Outlook}
\label{sec:outlook}

In this paper, we explained Myria's execution model and our log collection and log analysis infrastructure and our visualization. We also evaluated what our current visualization offers to developers. Nonetheless, further improvements of the performance (Section~\ref{sec:performance}) and the visualization (Section~\ref{sec:vizimprovement}) are possible.


\subsection{Visualization and integration}
\label{sec:vizimprovement}

We plan better integration of the visualization into the web interface and automatically redirect users to the overview visualization when they submit a long running query. The visualization can then be used to help estimating the progress of the query execution.

In addition to a better integration into the user interface, we plan to improve the Gantt chart for operator visualization to better present dependencies and explicitly show nesting. Additionally, the fact that not all state changes are possible (see Figure~\ref{fig:states} for a state diagram of possible state changes) allows us to develop a visualization that avoids redundant information. We already have some mock-ups that we created in response to what we saw in our charts but plan to first finish the back end to make it easier to adapt the data format.

\begin{figure}[h]
  \begin{center}
    \includegraphics[width=.5\textwidth]{states.pdf}
  \end{center}
  \caption{Possible state changes of non-leaf and non-root operators.}
  \label{fig:states}
\end{figure}

Another small improvement that we plan to implement is to show how many tuples were send to the same worker and how many tuples had to be send to other servers instead of just one number.


\subsection{Performance}
\label{sec:performance}

We plan to improve the performance of the back-end by storing the data in the Myria database as described in Section~\ref{sec:collect}. This will also simplify the code that analyzes the logs as we can issue queries to the database instead of calculating for example joins manually.

The performance of the front-end will be improved by adapting the data schema to a format that integrates more tightly with the visualization and removes redundant information.

% \subsection{Estimate computation/network overhead}
% \label{sec:overhead}

% A further question is  how can we get insightful information from the logging and visualization. To help us improving query plan rewriting and efficiently allocate resource for a query, we might want to reason about what factor contribute most to the running time of the query plan from the logging/visualization. In a pipelined and asynchronous query execution, communication (via network) and computation are overlapped. There would be no accurate measure of the communication time and computation time for the whole system.  So we would like to ask following questions.

% \noindent\textbf{Assume no communication time}.  That is to assume that we can have an underlying network with infinite bandwidth and zero latency. Based on the logging, we want to infer how much the running time could be improved given this assumption. This would be a measure of how expensive the computation is and could demonstrate the best performance gain we can have if we make the communication faster.

% \noindent\textbf{Assume no computation time}.  That is to assume that we can have infinitely fast computation hardware. Given this assumption, we want to infer how much the running time could be improved. This would be a measure of how expensive the communication is.

% \noindent\textbf{Proposed solution}.  Based on the logging information, we can build a temporal state transition graph of the query execution. This graph will consist of the temporal state information of each query fragment in each worker. Combined with the query plan, which contains the dependency between different operators, we want to develop algorithms to infer the running time given different assumptions.


\bibliographystyle{plain}
\bibliography{references}

\end{document}